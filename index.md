---
layout: default
---

<p>&nbsp;</p>
## About
Hi! I am a postdoc at Stanford working with Prof. Tatsu Hashimoto, Prof. Percy Liang, and Prof. James Zou.
I received my PhD from MIT, where I was fortunate to be advised by [Prof. Aleksander Mądry](https://madrylab.csail.mit.edu/).


I'm currently interested in understanding and improving machine learning (ML) methodology
through the *lens of data*. Some questions I think about include:
 - How do we *attribute* model predictions back to training data?
 - How do we *select* the right data for a given task?
 - Can we derive insights about ML phenomena (e.g., scaling laws, emergence, in-context learning) through this lens?

I'm also more broadly interested in the science of machine learning/deep learning.


<span style="color:green">[News]</span>  **I co-presented a tutorial at ICML '24 on Data Attribution at Scale: [[video](https://icml.cc/virtual/2024/tutorial/35228)] [[notes](https://ml-data-tutorial.org/)]!**


<p>&nbsp;</p>

## Bio
Previously at MIT, I worked on understanding statistical-computational tradeoffs in high-dimensional statistics with Prof. Guy Bresler for my SM thesis. Earlier during my PhD, I was supported by the MIT Akamai Presidential Fellowship and the Samsung Scholarship.

From 2016-18, I served in the Republic of Korea Army in the top signals intelligence unit as a researcher.

Prior to grad school, I received a BS in Computer Science from Cornell University (2011-14), where I was fortunate to work with Prof. Ramin Zabih and Prof. Bobby Kleinberg.

I have interned at Waymo, Dropbox, and Google.

<p>&nbsp;</p>

## Research

**Attribute-to-Delete: Machine Unlearning via Datamodel Matching**\
Kristian Georgiev\*, Roy Rinberg\*, <u>Sung Min Park*</u>, Shivam Garg\*, Andrew Ilyas, Aleksander Mądry, Seth Neel \
[[<u>arxiv</u>]](https://arxiv.org/abs/2410.23232) [[<u>blog</u>](https://t.co/QVgG2FlNmB)]


**The Journey, Not the Destination: How Data Guides Diffusion Models**\
Kristian Georgiev\*, Josh Vendrow\*, Hadi Salman, <u>Sung Min Park</u>, Aleksander Mądry \
[[<u>arxiv</u>]](https://arxiv.org/abs/2312.06205)

**TRAK: Attributing Model Behavior at Scale**\
<u>Sung Min Park*</u>, Kristian Georgiev\*, Andrew Ilyas\*, Guillaume Leclerc, Aleksander Mądry \
ICML 2023 (**Oral presentation**)\
[[<u>arxiv</u>]](https://arxiv.org/abs/2303.14186) [[<u>blog</u>](https://gradientscience.org/trak/)][[<u>code</u>](https://github.com/MadryLab/trak)]
[[<u>website</u>]](https://trak.csail.mit.edu/)[[<u>talk</u>](https://icml.cc/virtual/2023/oral/25526)]

**ModelDiff: A Framework for Comparing Learning Algorithms**\
Harshay Shah\*, <u>Sung Min Park*</u>, Andrew Ilyas\*, Aleksander Mądry \
ICML 2023\
[[<u>arxiv</u>]](https://arxiv.org/abs/2211.12491) [[<u>blog</u>](https://gradientscience.org/modeldiff/)][[<u>code</u>](https://github.com/MadryLab/modeldiff)]

**FFCV: Accelerating Training by Removing Data Bottlenecks**\
Guillaume Leclerc, Andrew Ilyas, Logan Engstrom, <u>Sung Min Park</u>, Hadi Salman, Aleksander Mądry \
CVPR 2023\
[[<u>code</u>](https://github.com/libffcv/ffcv)]

**A Data-Based Perspective on Transfer Learning**\
Saachi Jain\*, Hadi Salman\*, Alaa Khaddaj\*, Eric Wong, <u>Sung Min Park</u>, Aleksander Mądry\
CVPR 2023\
[[<u>arxiv</u>]](https://arxiv.org/abs/2207.05739) [[<u>blog</u>](https://gradientscience.org/data-transfer/)]

**Datamodels: Predicting Predictions from Training Data**\
Andrew Ilyas\*, <u>Sung Min Park*</u>, Logan Engstrom\*, Guillaume Leclerc, Aleksander Mądry\
ICML 2022\
[[<u>arxiv</u>]](https://arxiv.org/abs/2202.00622) [blog [<u>part 1</u>](https://gradientscience.org/datamodels-1/) [<u>part 2</u>](https://gradientscience.org/datamodels-2/)] [[<u>code</u>](https://github.com/MadryLab/datamodels)][[<u>data</u>]](https://github.com/MadryLab/datamodels-data)

**On Distinctive Properties of Universal Perturbations**\
<u>Sung Min Park</u>, Kuo-An Wei, Kai Xiao, Jerry Li, Aleksander Mądry\
2021\
[[<u>arxiv</u>]](https://arxiv.org/abs/2112.15329)

**Sparse PCA from Sparse Linear Regression**\
(α-β order) Guy Bresler, <u>Sung Min Park</u>, Madalina Persu\
NeurIPS 2018\
[[<u>arxiv</u>]](https://arxiv.org/abs/1811.10106) [[<u>poster</u>]](/assets/files/neurips_2018_poster.pdf) [[<u>code</u>]](https://github.com/sung-max/SPCAvSLR)

**On the Equivalence of Sparse Statistical Problems**\
Sung Min Park\
SM thesis 2016\
[[<u>pdf</u>]](/assets/files/sm_thesis.pdf)

**Structured learning of sum-of-submodular higher order energy functions**\
Alexander Fix, Thorsten Joachims, <u>Sung Min Park</u>, Ramin Zabih\
ICCV 2013\
[[<u>pdf</u>]](/assets/files/submodular.pdf)


<p>&nbsp;</p>
## Talks

* **Mar 2024** Stanford ML lunch
* **Jul 2023** [ICML Oral](https://icml.cc/virtual/2023/oral/25526)
* **May 2023** [LIDS & Stats Tea](https://lids.mit.edu/news-and-events/events/trak-attributing-model-behavior-scale)
* **May 2023** MIT MLTea
* **Apr 2023** [ML Collective Reading group](https://mlcollective.org/dlct/)
* **Feb 2023** [MIT LIDS Student Conference](https://lidsconf.mit.edu/2023/program.html)
* **Aug 2022** [UMN ML Seminar](https://sites.google.com/umn.edu/machine-learning)
* **Feb 2022** [LIDS & Stats Tea](https://lids.mit.edu/news-and-events/lids-stats-tea)
* **Jan 2022** [MIT LIDS Student Conference](https://lidsconf.mit.edu/2022/program.html)



<p>&nbsp;</p>
## Misc

**Region Detection and Geometry Prediction**\
Patent from work during Summer 2020 internship at Waymo\
[[<u>pdf</u>]](/assets/files/waymo_patent.pdf)

**Fourier Theoretic Probabilistic Inference over Permutations**\
Cornell, Spring 2014\
[[<u>pdf</u>]](/assets/files/fourier.pdf)

**Analysis of pipage method for k-max coverage**\
Cornell, Fall 2012\
[[<u>pdf</u>]](/assets/files/max_coverage.pdf)


<p>&nbsp;</p>
## Personal

I grew up between the Bay Area, Seoul, and Singapore, where I attended [SAS](https://www.sas.edu.sg/).

In my free time, I enjoy lifting, playing basketball, [rowing](/assets/img/rowing.jpg), watching the NBA (nuggets!), watching movies, and learning [physics](https://sung-max.github.io/learning-qft/) and math.
<p>&nbsp;</p>
